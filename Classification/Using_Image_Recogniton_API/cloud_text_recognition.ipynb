{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Texts From Images Using Google Cloud Vision\n",
    "\n",
    "This file uses the Google Cloud API to upload a file \n",
    "and get back a response from Google with all the texts that Google eas able extract from the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First step: pip install --upgrade google-api-python-client\n",
    "# Then, install oauth2client before running the code below\n",
    "\n",
    "from base64 import b64encode\n",
    "\n",
    "\n",
    "import googleapiclient.discovery\n",
    "from oauth2client.client import GoogleCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this values to match your project\n",
    "\n",
    "# Text.png is the image containing the texts I want to check\n",
    "IMAGE_FILE = \"text.png\"\n",
    "CREDENTIALS_FILE = \"credentials.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the Google Cloud-ML Service\n",
    "\n",
    "# Create an instance of the google service\n",
    "# Since I waant to use the cloud vision service, \n",
    "# I'll pass in 'vision', 'v1'and the credential file loaded above.\n",
    "credentials = GoogleCredentials.from_stream(CREDENTIALS_FILE)\n",
    "service = googleapiclient.discovery.build('vision', 'v1', credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file and convert it to a base64 encoding\n",
    "# The image file is loaded from disk which is then converted to a base64 encoded version\n",
    "# Google AAPI requires images to be uploaded in base64 format\n",
    "with open(IMAGE_FILE, \"rb\") as f:\n",
    "    image_data = f.read()\n",
    "    encoded_image_data = b64encode(image_data).decode('UTF-8')\n",
    "\n",
    "# Create the request object for the Google Vision API\n",
    "batch_request = [{\n",
    "    'image': {\n",
    "        'content': encoded_image_data\n",
    "    },\n",
    "    'features': [\n",
    "        {\n",
    "            'type': 'TEXT_DETECTION'\n",
    "        }\n",
    "    ]\n",
    "}]\n",
    "request = service.images().annotate(body={'requests': batch_request})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send the request to Google\n",
    "#The result will be stored in the response object\n",
    "response = request.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for errors\n",
    "if 'error' in response:\n",
    "    raise RuntimeError(response['error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results\n",
    "extracted_texts = response['responses'][0]['textAnnotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEATRICE\n",
      "I pray you, is Signior Mountanto returned from the\n",
      "wars or no?\n",
      "Messenger\n",
      "I know none of that name, lady: there was none such\n",
      "in the army of any sort,\n",
      "LEONATO\n",
      "What is he that you ask for, niece?\n",
      "HERO\n",
      "My cousin means Signior Benedick of Padua.\n",
      "Messenger\n",
      "O, he's returned; and as pleasant as ever he was\n",
      "BEATRICE\n",
      "He set up his bills here in Messina and challenged\n",
      "Cupid at the flight; and my uncle's fool, reading\n",
      "the challenge, subscribed for Cupid, and challenged\n",
      "him at the bird-bolt. I pray you, how many hath he\n",
      "killed and eaten in these wars? But how many hath\n",
      "he killed? for indeed I promised to eat all of his killing\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the first piece of text found in the image\n",
    "extracted_text = extracted_texts[0]\n",
    "print(extracted_text['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vertices': [{'x': 16, 'y': 9}, {'x': 794, 'y': 9}, {'x': 794, 'y': 1038}, {'x': 16, 'y': 1038}]}\n"
     ]
    }
   ],
   "source": [
    "# Print the location where the text was detected\n",
    "#This lists the pixel coordinates where thetexts were pulled\n",
    "print(extracted_text['boundingPoly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
