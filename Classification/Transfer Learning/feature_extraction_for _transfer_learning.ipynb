{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic idea is that neural networks learn to detect simple patterns in the top layer,\n",
    "and then the next layer uses that information to look for slightly more complex patterns \n",
    "and so on, down through all the convolutional layers. \n",
    "But the final layer of the neural network is a densely connected layer that uses the information from the convolutional layers to decide which object is in the image. \n",
    "With transfer learning, we're gonna start with a neural network that's already been trained to recognize objects from a large dataset like ImageNet. \n",
    "To reuse this neural network with new data, \n",
    "we can simply slice off the last layer.\n",
    "\n",
    "We'll keep all the layers that detect patterns, but remove the part that maps those patterns to specific objects.\n",
    "We'll call this pre-trained neural network a feature extractor because we're using it to extract training features from images. \n",
    "Next, we'll create a new neural network to replace the last layer in the original network. \n",
    "This is the only part that we'll have to train ourselves. When we build our new image recognition system, we'll pass our new training images through the feature extractor and save the results for each training image to a file. \n",
    "Then, we'll use those extracted features to train the new neural network.\n",
    "\n",
    "\n",
    "Transfer learning helps you to reduce the time spend in building a new neural network from sxratch.\n",
    "Transfer learning is also very useful if you have small amount of training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import joblib\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to folders with training data\n",
    "dog_path = Path(\"training_data\") / \"dogs\"\n",
    "not_dog_path = Path(\"training_data\") / \"not_dogs\"\n",
    "\n",
    "\n",
    "images = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The first step is to load all images that are not dogs\n",
    "\n",
    "# Load all the not-dog images\n",
    "for img in not_dog_path.glob(\"*.png\"):\n",
    "    # Load the image from disk\n",
    "    img = image.load_img(img)\n",
    "\n",
    "    # Convert the image to a numpy array\n",
    "    image_array = image.img_to_array(img)\n",
    "\n",
    "    # Add the image to the list of images\n",
    "    images.append(image_array)\n",
    "\n",
    "    # For each 'not dog' image, the expected value should be 0\n",
    "    labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the dog images. The only difference between loading the images that are not dogs\n",
    "# and loading the ones that are dogs is that the number 1 is appended to the labels or picturre of the dog\n",
    "for img in dog_path.glob(\"*.png\"):\n",
    "    # Load the image from disk\n",
    "    img = image.load_img(img)\n",
    "\n",
    "    # Convert the image to a numpy array\n",
    "    image_array = image.img_to_array(img)\n",
    "\n",
    "    # Add the image to the list of images\n",
    "    images.append(image_array)\n",
    "\n",
    "    # For each 'dog' image, the expected value should be 1\n",
    "    labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single numpy array with all the images we loaded\n",
    "x_train = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also convert the labels to a numpy array\n",
    "y_train = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize image data to 0-to-1 range\n",
    "#When the image is processed, we need to remember which images were dogs and which ones were not dogs\n",
    "#If the images are dog, we add 1 and wheen the images are not dogs, we add 0\n",
    "x_train = vgg16.preprocess_input(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 141s 2us/step\n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained neural network to use as a feature extractor\n",
    "#The new neral network is created here by uding the VGG16 and passing the weights, input_shape and include_tops\n",
    "#The top is the last layer of the neural network so include_top=False means that we want to exclude the last layer of the neural network \n",
    "#\n",
    "pretrained_nn = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for each image (all in one pass)\n",
    "#Let's feed all of our images into the neural network and capture the results\n",
    "features_x = pretrained_nn.predict(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x_train.dat']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the array of extracted features to a file\n",
    "#The library joblib helps with saving these data \n",
    "joblib.dump(features_x, \"x_train.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_train.dat']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the matching array of expected values to a file\n",
    "joblib.dump(y_train, \"y_train.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These extracted features will be used to train a new neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
